[environment]
init_m_target_depth = 5
final_m_target_depth = 30
target_depth_increment = 1

[neuralnetwork]
; available type Resnet or ResnetTransformer or MLP

architecture = Resnet
num_blocks = 5
num_channels = 128
num_policy_channels = 64
num_value_channels = 8
batch_norm_momentum = 0.9
kernel_size = 3

; architecture = MLP
; width = 64
; depth_common = 5
; depth_phead = 2
; depth_vhead = 2
; use_batch_norm = True
; batch_norm_momentum = 0.1
; dropout_rate = 0.2

; architecture = ResnetTransformer 
; num_blocks = 5
; num_channels = 32
; num_policy_channels = 32
; num_value_channels = 32
; batch_norm_momentum = 0.9
; kernel_size = 3
; num_transformer_heads = 8
; transformer_mlp_dim = 64
; transformer_embed_dim = 32

; architecture = VisionTransformer
; resnet_num_blocks = 2
; resnet_num_channels = 64
; transformer_num_heads = 4
; transformer_num_layers = 1
; transformer_mlp_dim = 256
; transformer_patches_size = 3
; transformer_hidden_size = 128
; batch_norm_momentum = 1.0
; kernel_size = 3

[replay_memory]
; number of game to store in memory
capacity = 8192

[alphazero_selfplay]
num_iterations = 400
max_nodes = 200
dirichlet_alpha = 1.0
dirichlet_epsilon = 0.25
temperature = 0.6
puct_c = 4.0
; single player game
discount = 1.0

[alphazero_evaluation]
num_iterations = 400
max_nodes = 200
dirichlet_epsilon = 0.05
temperature = 0.0
puct_c = 2.0
; single player game
discount = 1.0

[trainer]
; number of games to collect in parallel
batch_size = 64
; total number of games per epoch is batch_size*collection_steps_per_epoch
collection_steps_per_epoch = 16
; number of games to learn from per training steps
train_batch_size = 64
; before epoch starts, warmup_steps*batch_size games are collected
warmup_steps = 16
; optimizer (adam or adamw or sgd)
optimizer = adam
; learning rate
optimizer_lr = 0.001
; l2 regularization
l2_reg_lambda = 0.0000
; number of epochs (per target_depth)
num_epochs = 10
; extra epochs after increasing target_depth to maximum
extra_epochs = 50

[saving]
; directory to save checkpoint
bckp_dir = ./data/
; make a subdirectory with the datetime at run
use_date = True
