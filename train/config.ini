[environment]
init_m_target_depth = 2
final_m_target_depth = 30
target_depth_increment = 1

[neuralnetwork]
; available type Resnet or ResnetTransformer
architecture = ResnetTransformer
num_blocks = 5
num_channels = 128
num_policy_channels = 32
num_value_channels = 32
batch_norm_momentum = 0.1
kernel_size = 3
; below ResnetTransformer options
num_transformer_heads = 4
transformer_mlp_dim = 256
transformer_embed_dim = 128

[replay_memory]
; number of game to store in memory
capacity = 2_048

[alphazero_selfplay]
num_iterations = 200
max_nodes = 200
dirichlet_alpha = 1.0
dirichlet_epsilon = 0.25
temperature = 0.6
puct_c = 4.0
; single player game
discount = 1.0

[alphazero_evaluation]
num_iterations = 200
max_nodes = 200
dirichlet_epsilon = 0.05
temperature = 0.0
puct_c = 2.0
; single player game
discount = 1.0

[trainer]
; number of games to collect in parallel
batch_size = 64
; total number of games per epoch is batch_size*collection_steps_per_epoch
collection_steps_per_epoch = 16
; number of games to learn from per training steps
train_batch_size = 64
; before epoch starts, warmup_steps*batch_size games are collected
warmup_steps = 16
; learning rate (adam)
optimizer_lr = 0.001
; l2 regularization
l2_reg_lambda = 0.0001
; number of epochs (per target_depth)
num_epochs = 10

[saving]
; directory to save checkpoint
bckp_dir = ./data/
; make a subdirectory with the datetime at run
use_date = True
