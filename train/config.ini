[environment]
init_m_target_depth = 3
final_m_target_depth = 30
target_depth_increment = 1

[neuralnetwork]
; available type Resnet or ResnetTransformer or MLP

;architecture = Resnet
;num_blocks = 5
;num_channels = 128
;num_policy_channels = 32
;num_value_channels = 32
;batch_norm_momentum = 0.1
;kernel_size = 3

architecture = MLP
width = 64
depth_common = 5
depth_phead = 2
depth_vhead = 2
use_batch_norm = True
batch_norm_momentum = 0.1
dropout_rate = 0.2

;architecture = ResnetTransformer 
;num_blocks = 5
;num_channels = 128
;num_policy_channels = 32
;num_value_channels = 32
;batch_norm_momentum = 0.1
;kernel_size = 3
;num_transformer_heads = 4
;transformer_mlp_dim = 256
;transformer_embed_dim = 128

[replay_memory]
; number of game to store in memory
capacity = 2_048

[alphazero_selfplay]
num_iterations = 200
max_nodes = 200
dirichlet_alpha = 1.0
dirichlet_epsilon = 0.25
temperature = 0.6
puct_c = 4.0
; single player game
discount = 1.0

[alphazero_evaluation]
num_iterations = 200
max_nodes = 200
dirichlet_epsilon = 0.05
temperature = 0.0
puct_c = 2.0
; single player game
discount = 1.0

[trainer]
; number of games to collect in parallel
batch_size = 64
; total number of games per epoch is batch_size*collection_steps_per_epoch
collection_steps_per_epoch = 16
; number of games to learn from per training steps
train_batch_size = 64
; before epoch starts, warmup_steps*batch_size games are collected
warmup_steps = 16
; learning rate (adam)
optimizer_lr = 0.001
; l2 regularization
l2_reg_lambda = 0.0001
; number of epochs (per target_depth)
num_epochs = 10
; extra epochs after increasing target_depth to maximum
extra_epochs = 100

[saving]
; directory to save checkpoint
bckp_dir = ./data/
; make a subdirectory with the datetime at run
use_date = True
